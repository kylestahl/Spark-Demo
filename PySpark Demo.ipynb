{"nbformat_minor": 2, "nbformat": 4, "cells": [{"source": "### Connect to Hive with Hive Context", "cell_type": "markdown", "metadata": {}}, {"source": "A Spark context is already initialized when pyspark starts up in the Jupyter Notebook. To connect to Hive, we also need to create a **Hive Context.**", "cell_type": "markdown", "metadata": {}}, {"source": "sc", "cell_type": "code", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "Waiting for a Spark session to start..."}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "Waiting for a Spark session to start..."}, "metadata": {}}, {"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "<SparkContext master=yarn appName=Apache Toree>"}, "execution_count": 1}], "metadata": {"trusted": true}}, {"source": "from pyspark.sql import HiveContext\nhive_context = HiveContext(sc)", "cell_type": "code", "execution_count": 2, "outputs": [], "metadata": {"trusted": true}}, {"source": "hive_context.sql(\"show tables\").show()", "cell_type": "code", "execution_count": 3, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------+---------+-----------+\n|database|tableName|isTemporary|\n+--------+---------+-----------+\n| default|  hr_data|      false|\n+--------+---------+-----------+\n\n"}], "metadata": {"trusted": true}}, {"source": "### Pull data into Spark Memory", "cell_type": "markdown", "metadata": {}}, {"source": "With the `.sql` method on the hive context, we can pull data from Hive with traditional SQL queries. I am just going to pull the full data set in, but with this syntax you can perform any SQL commands on all of the databases and tables stored in Hive", "cell_type": "markdown", "metadata": {}}, {"source": "hr_data = hive_context.sql(\"SELECT * FROM hr_data\")", "cell_type": "code", "execution_count": 4, "outputs": [], "metadata": {"trusted": true}}, {"source": "hr_data.show(5)", "cell_type": "code", "execution_count": 5, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\n|satisfaction|last_eval|num_project|hours|years_at_company|work_accident|quit|promotion|department|salary|\n+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\n|        null|     null|       null| null|            null|         null|null|     null|     sales|salary|\n|        0.38|     0.53|          2|  157|               3|            0|   1|        0|     sales|   low|\n|         0.8|     0.86|          5|  262|               6|            0|   1|        0|     sales|medium|\n|        0.11|     0.88|          7|  272|               4|            0|   1|        0|     sales|medium|\n|        0.72|     0.87|          5|  223|               5|            0|   1|        0|     sales|   low|\n+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\nonly showing top 5 rows\n"}], "metadata": {"trusted": true}}, {"source": "### Analyze Data with Spark DataFrame", "cell_type": "markdown", "metadata": {}}, {"source": "After we pulled the data with the above SQL command it is stored in Sparks memory as a dataframe. There are two main ways to manipulate data with Spark. You have run SQL queries on Hive tables (as seen above) and you can chain commands together in a similar style from pythons `pandas` library. I will run the same data manipluations that were done in Hive to illustrate this functionality. ", "cell_type": "markdown", "metadata": {}}, {"source": "hr_data.printSchema()", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- satisfaction: float (nullable = true)\n |-- last_eval: float (nullable = true)\n |-- num_project: integer (nullable = true)\n |-- hours: integer (nullable = true)\n |-- years_at_company: integer (nullable = true)\n |-- work_accident: integer (nullable = true)\n |-- quit: integer (nullable = true)\n |-- promotion: integer (nullable = true)\n |-- department: string (nullable = true)\n |-- salary: string (nullable = true)\n\n"}], "metadata": {"trusted": true}}, {"source": "The first thing we need to do is drop the NA rows.", "cell_type": "markdown", "metadata": {}}, {"source": "hr_data = hr_data.dropna()", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {"trusted": true}}, {"source": "hr_data.groupby('department') \\\n    .agg({'satisfaction':'mean', 'quit':'count'}) \\\n    .orderBy('count(quit)',ascending=False) \\\n    .show()", "cell_type": "code", "execution_count": 8, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----------+-----------+------------------+\n| department|count(quit)| avg(satisfaction)|\n+-----------+-----------+------------------+\n|      sales|       4140|0.6144468597617846|\n|  technical|       2720|0.6078970591263736|\n|    support|       2229|0.6182996854854571|\n|         IT|       1227|0.6181418096985192|\n|product_mng|        902|0.6196341452636899|\n|  marketing|        858|0.6186013972356325|\n|      RandD|        787|0.6198221083631055|\n| accounting|        767|0.5821512387057638|\n|         hr|        739|0.5988092017794817|\n| management|        630|0.6213492063657632|\n+-----------+-----------+------------------+\n\n"}], "metadata": {"trusted": true}}, {"source": "hr_data.groupby(['salary','quit']). \\\n    mean('satisfaction'). \\\n    orderBy('avg(satisfaction)',ascending=False) \\\n    .show()", "cell_type": "code", "execution_count": 9, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+----+------------------+\n|salary|quit| avg(satisfaction)|\n+------+----+------------------+\n|medium|   0|0.6688750243022512|\n|   low|   0| 0.668102643885657|\n|  high|   0|0.6518787871514048|\n|   low|   1| 0.441247697521694|\n|medium|   1|0.4385497335997964|\n|  high|   1|0.4345121940643322|\n+------+----+------------------+\n\n"}], "metadata": {"trusted": true}}, {"source": "### Machine Learning with Spark ML", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import (StringIndexer, OneHotEncoder, VectorAssembler)", "cell_type": "code", "execution_count": 10, "outputs": [], "metadata": {"trusted": true}}, {"source": "hr_data.show(5)", "cell_type": "code", "execution_count": 11, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\n|satisfaction|last_eval|num_project|hours|years_at_company|work_accident|quit|promotion|department|salary|\n+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\n|        0.38|     0.53|          2|  157|               3|            0|   1|        0|     sales|   low|\n|         0.8|     0.86|          5|  262|               6|            0|   1|        0|     sales|medium|\n|        0.11|     0.88|          7|  272|               4|            0|   1|        0|     sales|medium|\n|        0.72|     0.87|          5|  223|               5|            0|   1|        0|     sales|   low|\n|        0.37|     0.52|          2|  159|               3|            0|   1|        0|     sales|   low|\n+------------+---------+-----------+-----+----------------+-------------+----+---------+----------+------+\nonly showing top 5 rows\n\n"}], "metadata": {"trusted": true}}, {"source": "**Turn String variables into Factors of (1, 2, 3, ...)**", "cell_type": "markdown", "metadata": {}}, {"source": "dept_indexer = StringIndexer(inputCol = 'department', outputCol = 'dept_indexer')\nsalary_indexer = StringIndexer(inputCol = 'salary', outputCol = 'salary_indexer')", "cell_type": "code", "execution_count": 12, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Turn factors into binary (1,0) variables**", "cell_type": "markdown", "metadata": {}}, {"source": "dept_encoder = OneHotEncoder(inputCol = 'dept_indexer', outputCol = 'dept_encoder')\nsalary_encoder = OneHotEncoder(inputCol = 'salary_indexer', outputCol = 'salary_encoder')", "cell_type": "code", "execution_count": 13, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Assemble all indpendent variables into one data object**", "cell_type": "markdown", "metadata": {}}, {"source": "assembler = VectorAssembler(inputCols = ['dept_encoder','salary_encoder','satisfaction',\n                                        'last_eval','num_project','hours','years_at_company',\n                                        'work_accident','promotion'],\n                            outputCol = 'features') ", "cell_type": "code", "execution_count": 14, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Initialize Logistic Regression**", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.classification import LogisticRegression\nlog_reg = LogisticRegression(labelCol = 'quit')", "cell_type": "code", "execution_count": 15, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Assemble Pipeline**", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[dept_indexer,salary_indexer,dept_encoder,salary_encoder, assembler, log_reg])", "cell_type": "code", "execution_count": 16, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Train, test, split**", "cell_type": "markdown", "metadata": {}}, {"source": "train_hr ,test_hr = hr_data.randomSplit([0.7,0.3])", "cell_type": "code", "execution_count": 17, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Initialize Model Evaluator**", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.ml.evaluation import BinaryClassificationEvaluator\nmodel_eval = BinaryClassificationEvaluator(rawPredictionCol = 'rawPrediction',\n                                           labelCol = 'quit')", "cell_type": "code", "execution_count": 18, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Fit the model**", "cell_type": "markdown", "metadata": {}}, {"source": "fitted_model = pipeline.fit(train_hr)", "cell_type": "code", "execution_count": 19, "outputs": [], "metadata": {"trusted": true}}, {"source": "**Use fitted model to get predictions**", "cell_type": "markdown", "metadata": {}}, {"source": "predictions = fitted_model.transform(test_hr)", "cell_type": "code", "execution_count": 20, "outputs": [], "metadata": {"trusted": true}}, {"source": "predictions['quit','rawPrediction','probability','prediction'].limit(5).toPandas()", "cell_type": "code", "execution_count": 21, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "   quit                      rawPrediction                       probability  \\\n0     1  [-0.799246083323, 0.799246083323]  [0.310186812054, 0.689813187946]   \n1     1  [-0.686849340204, 0.686849340204]  [0.334734319313, 0.665265680687]   \n2     1    [-1.34333017428, 1.34333017428]  [0.206962946034, 0.793037053966]   \n3     1    [-0.70476239021, 0.70476239021]  [0.330757191667, 0.669242808333]   \n4     1    [-0.98143652301, 0.98143652301]  [0.272606839105, 0.727393160895]   \n\n   prediction  \n0         1.0  \n1         1.0  \n2         1.0  \n3         1.0  \n4         1.0  "}, "execution_count": 21}], "metadata": {"trusted": true}}, {"source": "**Find accuracy**", "cell_type": "markdown", "metadata": {}}, {"source": "The only to binary classification metrics allowed are \"areaUnderROC\", \"areaUnderPR\", the default is AUROC. Below in SparkR I calculate accuracy so this isn't an apples to apples comparision. ", "cell_type": "markdown", "metadata": {}}, {"source": "not_accuracy = model_eval.evaluate(predictions)\nprint not_accuracy", "cell_type": "code", "execution_count": 22, "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.829864990689\n"}], "metadata": {"trusted": true}}, {"source": "This is the apples to apples comparison", "cell_type": "markdown", "metadata": {}}, {"source": "# Total number of rows\nfloat(predictions.count())", "cell_type": "code", "execution_count": 23, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "4474.0"}, "execution_count": 23}], "metadata": {"trusted": true}}, {"source": "# Number of rows where the prediction is correct\npredictions.filter(((predictions.quit==1) & (predictions.prediction==1)) | \\\n                   ((predictions.quit==0) & (predictions.prediction==0))).count()", "cell_type": "code", "execution_count": 24, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "3533"}, "execution_count": 24}], "metadata": {"trusted": true}}, {"source": "accuracy = predictions.filter(((predictions.quit==1) & (predictions.prediction==1)) | \\\n                   ((predictions.quit==0) & (predictions.prediction==0))).count() / float(predictions.count())\nprint accuracy", "cell_type": "code", "execution_count": 25, "outputs": [{"output_type": "stream", "name": "stdout", "text": "0.789673670094\n"}], "metadata": {"trusted": true}}], "metadata": {"kernelspec": {"display_name": "Apache Toree - PySpark", "name": "apache_toree_pyspark", "language": "python"}, "language_info": {"mimetype": "text/x-ipython", "name": "python", "pygments_lexer": "python", "version": "2.7.13\n", "file_extension": ".py", "codemirror_mode": "text/x-ipython"}}}